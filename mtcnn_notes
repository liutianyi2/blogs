1.预处理

min_size：预估所有图片中最小人脸的像素长宽。

minl = np.amin([h, w])

m = 12.0 / min_size

minl = minl * m

scales += [m * np.power(factor, factor_count)]

缩放比例scales需要*m，可以看成从一开始原图就*m，从而使得最小人脸达到能够被识别的大小（12 * 12）。

2.pnet

只有pnet需要图片金字塔迭代，因为rnet、onet的输入都已经是疑似有人脸的、尺寸固定的正方形。

im_data = (im_data - 127.7) * 0.0078125

把rgb的[0, 255]转成[-1, 1]，据说在训练时能加速。

img_y = np.transpose(img_x, (0, 2, 1, 3))，以及代码中的各种transpose转置矩阵之后又转回来，原作者sandberg解释是参数文件det123是从caffe训练来的，而当初训练时就需要转置。我们在看代码时可以忽略。

单图片计算pnet输入为shape (1,w,h,3)的图片，输出为(1,w/2-5,h/2-5,2)的概率矩阵和(1,w/2-5,h/2-5,4)的偏移矩阵，是3个卷积核为3的VALID、步长为1的卷积层和一个步长为2、卷积核为2的池化层的结果。对于概率矩阵和偏移矩阵x、y坐标的解读，可以看成是金字塔化后的原图中心点为((x+5)*2,(y+5)*2)，边长为12的正方形包含人脸的概率和需要对左下、右上角点坐标的调整。

为什么要坐标调整？原图本来可能还有更多的人脸信息但是压缩并且只截取了正方形；或者正方形内的人脸比例太小了。偏移矩阵告诉我们在原图的基础上把正方形拓展或缩小成和人脸更对应的矩形。

nms(boxes.copy(), 0.5, 'Union')

从人脸概率最大的框开始，去除和这些框大面积重复的框，union表示交集占两个框大小的总比；在onet中用到了min表示交集占最小框的比例，去除大包小的效果更明显。而union比如小框有12*12，大框25*25，即使小框完全在大框内也不会被去除。

total_boxes = rerec(total_boxes.copy())。

对于矩形，转化成包含矩形的同中心点的正方形，便于后面的net处理。

3.rnet

先把pnet输出的正方形resize为24*24。

输入为(bbox_count, 24, 24, 3)，全联接层前输出为(bbox_count,3,3,64)，是一个3*3的卷积层(24-2=22)->3*3 步长为2的池化层((22)/2=11)->3*3卷积(11-2=9)->3*3池化(9/2=4)->2*2卷积(4-1=3)得到的。

最后经过全联接层输出为(bbox_count,1)和(bbox_count,4)的一个概率矩阵和左下、右上坐标调整矩阵。

nms和rerec同pnet。

4.onet

对于rnet筛选后的人脸框，先resize为48*48。

输入为(bbox_count, 48, 48, 3)，输出为(bbox_count,1)\(bbox_count,4)\(bbox_count,10)的三个矩阵，分别对应概率、人脸框偏移和特征点坐标。
